{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd1a6df8ca34945b89923922635214e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper # 30초 cpu 기준\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"beomi/KoAlpaca-Polyglot-5.8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x):\n",
    "    a = pipe(\n",
    "        f'### 질문: {x}\\n\\n### 답변:', \n",
    "        max_new_tokens=50, \n",
    "        return_full_text=False, \n",
    "        do_sample=True,\n",
    "        top_k=5,\n",
    "        top_p=0.7,\n",
    "        temperature=0.7,\n",
    "        early_stopping=True,\n",
    "        repetition_penalty=1.0,\n",
    "    )\n",
    "    print(a[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\OpenAI_lecture\\base_codeset_test\\.venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요.\n",
      "\n",
      "이라는 표현은 올바른 표현이 아닙니다.\n",
      "\n",
      "대신, 안녕하세요. (X)가 맞는 표현입니다.\n",
      "\n",
      "'안녕하세요.'는 존댓말이기 때문에 사람을 높이\n"
     ]
    }
   ],
   "source": [
    "# repetition_penalty = 1.0, top_k = 5\n",
    "gen(\"안녕하세요.\") #top_p = 0.9일때, 초 / top_p = 0.8일때, 초 / top_p = 0.7(do_sample=True)일때, 초 / top_p = 0.7(do_sample=False)일때, 초 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\OpenAI_lecture\\base_codeset_test\\.venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 제 이름은 John이고, 나이는 25입니다. 고등학교 때부터 코딩을 좋아했으며, 대학에서는 컴퓨터 공학을 전공했습니다. 앞으로 소프트웨어 개발 분야에서 일하고 싶습니다. 혹시 M\n"
     ]
    }
   ],
   "source": [
    "# repetition_penalty = 1.0\n",
    "gen(\"안녕하세요.\") #top_p = 0.9일때, 초 / top_p = 0.8일때, 초 / top_p = 0.7(do_sample=True)일때, 69초 / top_p = 0.7(do_sample=False)일때, 60초 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\OpenAI_lecture\\base_codeset_test\\.venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\dev\\OpenAI_lecture\\base_codeset_test\\.venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 제 이름은 John이고, 나이는 25입니다. 저는 소프트웨어 개발 분야에서 일하고 있습니다. 관심있는 기술분야가 컴퓨터 프로그래밍 언어여서, 코딩을 배우려고 합니다. 최근에는\n"
     ]
    }
   ],
   "source": [
    "# repetition_penalty = 1.2\n",
    "gen(\"안녕하세요.\") #top_p = 0.9일때, 82초 / top_p = 0.8일때, 66초 / top_p = 0.7(do_sample=True)일때, 54초 / top_p = 0.7(do_sample=False)일때, 65초 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\OpenAI_lecture\\base_codeset_test\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '안녕하세요.\\n\\n### 맥락:\\n안녕하세요?\\n여전히 답변이'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"안녕하세요\") # 20초"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
